{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - Ⅱ\n",
    "-미국 보스턴 지역의 집값을 13개의 Feature를 이용하여 예측하는 모델을 만들어 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Data\n",
    "-Bostion Housing 데이터셋\n",
    "-보스턴 지역의 주변 환경에 대한 수치값과 집값 데이터\n",
    "- Sample수 : 506개\n",
    "- Feature : 14개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('./BostonHousing.csv') #csv(comma-separated values)파일 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio   black  lstat  medv  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_raw.shape) # Dataset의 크기 확인\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "# X값 coulumn\n",
    "x = df_raw.drop(['medv'],axis=1)\n",
    "\n",
    "# y값 column\n",
    "y = df_raw['medv']\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train의 크기:  (354, 13)\n",
      "y_train의 크기:  (354,) \n",
      "\n",
      "x_test의 크기:  (152, 13)\n",
      "y_test의 크기:  (152,)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#학습데이터와 테스트데이터를 일정비율로 나누기\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=1234)\n",
    "\n",
    "#학습 데이터\n",
    "print(\"x_train의 크기: \",x_train.shape)\n",
    "print(\"y_train의 크기: \",y_train.shape,'\\n')\n",
    "\n",
    "#테스트 데이터 \n",
    "print(\"x_test의 크기: \",x_test.shape)\n",
    "print(\"y_test의 크기: \",y_test.shape)\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 데이터 Scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scale = scaler.transform(x_train)  # x_train_scale은 numpy ndarray \n",
    "\n",
    "\n",
    "#테스트 데이터 Scaling\n",
    "x_test_scale = scaler.transform(x_test)    # x_test_scale은 numpy ndarray \n",
    "\n",
    "\n",
    "# Array-->Tensor\n",
    "x_train_tensor = torch.FloatTensor(x_train_scale)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values) #판다스 Series이므로 values를 사용해서 numpy ndarray로 가져오기\n",
    "\n",
    "x_test_tensor = torch.FloatTensor(x_test_scale)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([100, 13])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "#학습 데이터 배치화 시키기 \n",
    "train_data =  data_utils.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "dataloader =  data_utils.DataLoader(train_data, batch_size=100, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "#배치화된 데이터 확인\n",
    "for batch_idx, datas in enumerate(dataloader ):\n",
    "    \n",
    "    print(batch_idx)\n",
    "    print(datas[0].shape)  # x_train \n",
    "    print(datas[1].shape) # y_train\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter 정의\n",
    "input_size = 13\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 생성\n",
    "model = torch.nn.Linear(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실함수 생성\n",
    "criterion = torch.nn.MSELoss()\n",
    "#Optimizer 생성\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3]Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, Loss_train:265.64, Loss_test:158.33\n",
      "epoch:1, Loss_train:84.96, Loss_test:57.99\n",
      "epoch:2, Loss_train:49.71, Loss_test:30.11\n",
      "epoch:3, Loss_train:35.40, Loss_test:23.90\n",
      "epoch:4, Loss_train:18.66, Loss_test:22.17\n",
      "epoch:5, Loss_train:27.26, Loss_test:21.61\n",
      "epoch:6, Loss_train:20.33, Loss_test:21.50\n",
      "epoch:7, Loss_train:25.37, Loss_test:23.62\n",
      "epoch:8, Loss_train:28.30, Loss_test:22.70\n",
      "epoch:9, Loss_train:24.49, Loss_test:23.41\n",
      "epoch:10, Loss_train:11.09, Loss_test:22.76\n",
      "epoch:11, Loss_train:25.66, Loss_test:22.87\n",
      "epoch:12, Loss_train:11.19, Loss_test:23.04\n",
      "epoch:13, Loss_train:24.42, Loss_test:23.02\n",
      "epoch:14, Loss_train:29.66, Loss_test:23.11\n",
      "epoch:15, Loss_train:22.66, Loss_test:24.52\n",
      "epoch:16, Loss_train:25.48, Loss_test:24.31\n",
      "epoch:17, Loss_train:27.01, Loss_test:23.98\n",
      "epoch:18, Loss_train:14.07, Loss_test:23.88\n",
      "epoch:19, Loss_train:25.48, Loss_test:24.47\n",
      "epoch:20, Loss_train:19.50, Loss_test:23.97\n",
      "epoch:21, Loss_train:21.22, Loss_test:26.22\n",
      "epoch:22, Loss_train:22.63, Loss_test:26.13\n",
      "epoch:23, Loss_train:22.81, Loss_test:24.04\n",
      "epoch:24, Loss_train:40.84, Loss_test:28.14\n",
      "epoch:25, Loss_train:27.50, Loss_test:26.20\n",
      "epoch:26, Loss_train:27.24, Loss_test:25.14\n",
      "epoch:27, Loss_train:24.39, Loss_test:23.46\n",
      "epoch:28, Loss_train:10.74, Loss_test:23.36\n",
      "epoch:29, Loss_train:14.01, Loss_test:23.77\n",
      "epoch:30, Loss_train:30.79, Loss_test:26.41\n",
      "epoch:31, Loss_train:22.87, Loss_test:23.15\n",
      "epoch:32, Loss_train:21.64, Loss_test:22.99\n",
      "epoch:33, Loss_train:27.69, Loss_test:23.22\n",
      "epoch:34, Loss_train:17.72, Loss_test:23.14\n",
      "epoch:35, Loss_train:13.12, Loss_test:23.34\n",
      "epoch:36, Loss_train:21.02, Loss_test:24.38\n",
      "epoch:37, Loss_train:17.73, Loss_test:23.58\n",
      "epoch:38, Loss_train:20.98, Loss_test:23.90\n",
      "epoch:39, Loss_train:26.04, Loss_test:23.79\n",
      "epoch:40, Loss_train:23.10, Loss_test:23.91\n",
      "epoch:41, Loss_train:26.19, Loss_test:24.21\n",
      "epoch:42, Loss_train:20.25, Loss_test:23.68\n",
      "epoch:43, Loss_train:24.22, Loss_test:23.68\n",
      "epoch:44, Loss_train:27.31, Loss_test:25.12\n",
      "epoch:45, Loss_train:22.82, Loss_test:23.23\n",
      "epoch:46, Loss_train:21.99, Loss_test:23.66\n",
      "epoch:47, Loss_train:26.32, Loss_test:25.53\n",
      "epoch:48, Loss_train:26.98, Loss_test:23.82\n",
      "epoch:49, Loss_train:17.00, Loss_test:23.43\n",
      "epoch:50, Loss_train:29.60, Loss_test:23.79\n",
      "epoch:51, Loss_train:25.26, Loss_test:24.74\n",
      "epoch:52, Loss_train:31.26, Loss_test:26.95\n",
      "epoch:53, Loss_train:25.28, Loss_test:23.31\n",
      "epoch:54, Loss_train:21.99, Loss_test:23.30\n",
      "epoch:55, Loss_train:19.66, Loss_test:23.74\n",
      "epoch:56, Loss_train:27.90, Loss_test:23.83\n",
      "epoch:57, Loss_train:20.96, Loss_test:23.29\n",
      "epoch:58, Loss_train:19.31, Loss_test:23.37\n",
      "epoch:59, Loss_train:14.52, Loss_test:23.42\n",
      "epoch:60, Loss_train:20.86, Loss_test:23.83\n",
      "epoch:61, Loss_train:20.45, Loss_test:23.78\n",
      "epoch:62, Loss_train:22.97, Loss_test:23.36\n",
      "epoch:63, Loss_train:18.37, Loss_test:23.94\n",
      "epoch:64, Loss_train:23.22, Loss_test:24.28\n",
      "epoch:65, Loss_train:30.32, Loss_test:25.78\n",
      "epoch:66, Loss_train:24.09, Loss_test:24.05\n",
      "epoch:67, Loss_train:14.46, Loss_test:23.52\n",
      "epoch:68, Loss_train:37.36, Loss_test:24.14\n",
      "epoch:69, Loss_train:22.42, Loss_test:23.51\n",
      "epoch:70, Loss_train:15.10, Loss_test:23.05\n",
      "epoch:71, Loss_train:30.41, Loss_test:23.98\n",
      "epoch:72, Loss_train:28.77, Loss_test:26.18\n",
      "epoch:73, Loss_train:19.63, Loss_test:23.64\n",
      "epoch:74, Loss_train:22.84, Loss_test:23.78\n",
      "epoch:75, Loss_train:29.68, Loss_test:23.94\n",
      "epoch:76, Loss_train:25.16, Loss_test:26.50\n",
      "epoch:77, Loss_train:29.70, Loss_test:24.78\n",
      "epoch:78, Loss_train:21.76, Loss_test:25.13\n",
      "epoch:79, Loss_train:21.01, Loss_test:24.09\n",
      "epoch:80, Loss_train:23.41, Loss_test:24.51\n",
      "epoch:81, Loss_train:26.47, Loss_test:24.05\n",
      "epoch:82, Loss_train:20.06, Loss_test:25.34\n",
      "epoch:83, Loss_train:23.41, Loss_test:24.41\n",
      "epoch:84, Loss_train:17.63, Loss_test:24.82\n",
      "epoch:85, Loss_train:23.47, Loss_test:26.85\n",
      "epoch:86, Loss_train:21.48, Loss_test:24.85\n",
      "epoch:87, Loss_train:17.22, Loss_test:24.35\n",
      "epoch:88, Loss_train:29.37, Loss_test:24.65\n",
      "epoch:89, Loss_train:24.63, Loss_test:24.07\n",
      "epoch:90, Loss_train:31.22, Loss_test:24.69\n",
      "epoch:91, Loss_train:19.26, Loss_test:24.73\n",
      "epoch:92, Loss_train:28.39, Loss_test:24.73\n",
      "epoch:93, Loss_train:20.51, Loss_test:23.94\n",
      "epoch:94, Loss_train:23.50, Loss_test:24.15\n",
      "epoch:95, Loss_train:14.48, Loss_test:24.24\n",
      "epoch:96, Loss_train:26.27, Loss_test:25.00\n",
      "epoch:97, Loss_train:29.68, Loss_test:24.61\n",
      "epoch:98, Loss_train:19.55, Loss_test:24.38\n",
      "epoch:99, Loss_train:29.22, Loss_test:24.50\n",
      "epoch:100, Loss_train:25.53, Loss_test:25.96\n",
      "epoch:101, Loss_train:13.67, Loss_test:25.58\n",
      "epoch:102, Loss_train:27.75, Loss_test:24.43\n",
      "epoch:103, Loss_train:28.30, Loss_test:24.54\n",
      "epoch:104, Loss_train:27.16, Loss_test:26.37\n",
      "epoch:105, Loss_train:23.25, Loss_test:27.04\n",
      "epoch:106, Loss_train:28.90, Loss_test:24.56\n",
      "epoch:107, Loss_train:15.01, Loss_test:24.06\n",
      "epoch:108, Loss_train:38.49, Loss_test:26.61\n",
      "epoch:109, Loss_train:17.80, Loss_test:23.88\n",
      "epoch:110, Loss_train:24.38, Loss_test:25.55\n",
      "epoch:111, Loss_train:16.63, Loss_test:23.88\n",
      "epoch:112, Loss_train:18.72, Loss_test:24.69\n",
      "epoch:113, Loss_train:21.20, Loss_test:23.98\n",
      "epoch:114, Loss_train:21.66, Loss_test:25.26\n",
      "epoch:115, Loss_train:20.29, Loss_test:25.64\n",
      "epoch:116, Loss_train:23.14, Loss_test:24.52\n",
      "epoch:117, Loss_train:23.51, Loss_test:24.36\n",
      "epoch:118, Loss_train:27.22, Loss_test:25.12\n",
      "epoch:119, Loss_train:18.24, Loss_test:23.65\n",
      "epoch:120, Loss_train:28.00, Loss_test:23.78\n",
      "epoch:121, Loss_train:12.88, Loss_test:23.72\n",
      "epoch:122, Loss_train:23.72, Loss_test:25.39\n",
      "epoch:123, Loss_train:30.62, Loss_test:25.88\n",
      "epoch:124, Loss_train:24.82, Loss_test:24.71\n",
      "epoch:125, Loss_train:22.28, Loss_test:24.05\n",
      "epoch:126, Loss_train:20.78, Loss_test:24.43\n",
      "epoch:127, Loss_train:21.59, Loss_test:24.62\n",
      "epoch:128, Loss_train:27.43, Loss_test:23.36\n",
      "epoch:129, Loss_train:21.86, Loss_test:23.47\n",
      "epoch:130, Loss_train:23.63, Loss_test:23.41\n",
      "epoch:131, Loss_train:17.42, Loss_test:24.24\n",
      "epoch:132, Loss_train:24.08, Loss_test:23.79\n",
      "epoch:133, Loss_train:29.30, Loss_test:24.12\n",
      "epoch:134, Loss_train:26.41, Loss_test:24.00\n",
      "epoch:135, Loss_train:14.63, Loss_test:24.21\n",
      "epoch:136, Loss_train:21.80, Loss_test:25.00\n",
      "epoch:137, Loss_train:36.04, Loss_test:25.36\n",
      "epoch:138, Loss_train:25.43, Loss_test:24.32\n",
      "epoch:139, Loss_train:25.13, Loss_test:24.63\n",
      "epoch:140, Loss_train:18.48, Loss_test:24.28\n",
      "epoch:141, Loss_train:19.61, Loss_test:25.50\n",
      "epoch:142, Loss_train:25.88, Loss_test:24.93\n",
      "epoch:143, Loss_train:25.65, Loss_test:25.24\n",
      "epoch:144, Loss_train:21.58, Loss_test:24.11\n",
      "epoch:145, Loss_train:16.83, Loss_test:23.86\n",
      "epoch:146, Loss_train:23.56, Loss_test:23.74\n",
      "epoch:147, Loss_train:28.34, Loss_test:25.60\n",
      "epoch:148, Loss_train:23.63, Loss_test:23.74\n",
      "epoch:149, Loss_train:19.72, Loss_test:24.06\n",
      "epoch:150, Loss_train:32.23, Loss_test:24.70\n",
      "epoch:151, Loss_train:18.51, Loss_test:24.29\n",
      "epoch:152, Loss_train:25.92, Loss_test:24.85\n",
      "epoch:153, Loss_train:23.94, Loss_test:25.28\n",
      "epoch:154, Loss_train:25.20, Loss_test:24.10\n",
      "epoch:155, Loss_train:19.60, Loss_test:23.82\n",
      "epoch:156, Loss_train:32.49, Loss_test:25.81\n",
      "epoch:157, Loss_train:27.24, Loss_test:24.46\n",
      "epoch:158, Loss_train:18.73, Loss_test:23.83\n",
      "epoch:159, Loss_train:23.65, Loss_test:23.95\n",
      "epoch:160, Loss_train:27.18, Loss_test:24.53\n",
      "epoch:161, Loss_train:25.61, Loss_test:24.81\n",
      "epoch:162, Loss_train:40.23, Loss_test:26.18\n",
      "epoch:163, Loss_train:22.04, Loss_test:24.62\n",
      "epoch:164, Loss_train:24.77, Loss_test:25.22\n",
      "epoch:165, Loss_train:21.44, Loss_test:24.84\n",
      "epoch:166, Loss_train:24.69, Loss_test:23.83\n",
      "epoch:167, Loss_train:33.73, Loss_test:24.10\n",
      "epoch:168, Loss_train:21.90, Loss_test:23.99\n",
      "epoch:169, Loss_train:22.84, Loss_test:23.89\n",
      "epoch:170, Loss_train:25.98, Loss_test:25.48\n",
      "epoch:171, Loss_train:22.86, Loss_test:24.95\n",
      "epoch:172, Loss_train:20.78, Loss_test:25.19\n",
      "epoch:173, Loss_train:22.05, Loss_test:23.65\n",
      "epoch:174, Loss_train:16.29, Loss_test:23.67\n",
      "epoch:175, Loss_train:16.26, Loss_test:23.62\n",
      "epoch:176, Loss_train:24.53, Loss_test:23.35\n",
      "epoch:177, Loss_train:22.39, Loss_test:24.85\n",
      "epoch:178, Loss_train:16.64, Loss_test:23.18\n",
      "epoch:179, Loss_train:15.88, Loss_test:23.36\n",
      "epoch:180, Loss_train:20.10, Loss_test:23.66\n",
      "epoch:181, Loss_train:25.93, Loss_test:25.28\n",
      "epoch:182, Loss_train:20.83, Loss_test:24.98\n",
      "epoch:183, Loss_train:20.87, Loss_test:24.67\n",
      "epoch:184, Loss_train:14.06, Loss_test:24.61\n",
      "epoch:185, Loss_train:19.63, Loss_test:23.43\n",
      "epoch:186, Loss_train:21.96, Loss_test:24.27\n",
      "epoch:187, Loss_train:18.17, Loss_test:25.78\n",
      "epoch:188, Loss_train:21.19, Loss_test:24.13\n",
      "epoch:189, Loss_train:19.74, Loss_test:24.18\n",
      "epoch:190, Loss_train:26.45, Loss_test:24.20\n",
      "epoch:191, Loss_train:31.97, Loss_test:23.79\n",
      "epoch:192, Loss_train:32.12, Loss_test:27.55\n",
      "epoch:193, Loss_train:24.27, Loss_test:23.88\n",
      "epoch:194, Loss_train:19.78, Loss_test:23.77\n",
      "epoch:195, Loss_train:24.27, Loss_test:23.45\n",
      "epoch:196, Loss_train:20.75, Loss_test:24.09\n",
      "epoch:197, Loss_train:24.63, Loss_test:24.61\n",
      "epoch:198, Loss_train:24.84, Loss_test:24.53\n",
      "epoch:199, Loss_train:18.48, Loss_test:24.68\n",
      "epoch:200, Loss_train:18.87, Loss_test:24.10\n"
     ]
    }
   ],
   "source": [
    "## Running the model\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for epoch in range(n_epochs+1):\n",
    "    \n",
    "    for idx, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        \n",
    "        #Batch 학습\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(x_batch)\n",
    "        y_pred = y_pred.reshape(-1)\n",
    "        \n",
    "        loss_train = criterion(y_pred, y_batch)\n",
    "        \n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        #Validation\n",
    "        model.eval()\n",
    "        y_test_pred = model(x_test_tensor)\n",
    "        \n",
    "        y_test_pred = y_test_pred.reshape(-1)\n",
    "        \n",
    "        loss_test = criterion(y_test_pred, y_test_tensor)\n",
    "        \n",
    "        \n",
    "        \n",
    "   \n",
    "    train_loss.append(loss_train.item())\n",
    "    test_loss.append(loss_test.item())\n",
    "    print(\"epoch:{}, Loss_train:{:.2f}, Loss_test:{:.2f}\".format( epoch, train_loss[-1], test_loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss 값 plot\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(test_loss, label='test')\n",
    "plt.title('Model loss')\n",
    "plt.legend(loc= 'upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <Scaling>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip) Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x_in = \\frac{x_io - \\mu_i}{\\sigma_i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "[0.5 4. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.25"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = [[0, 0], [0, 0], [1, 8], [1, 8]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data_arr= np.array(data)\n",
    "\n",
    "print(data_arr.shape)\n",
    "print(np.mean(data_arr, axis= 0))\n",
    "data_arr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_arr_scaler=scaler.transform(data_arr)\n",
    "data_arr_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3. , -0.5]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform([[2, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1.]\n",
      " [-1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(data_arr_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data_arr_scaler, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_arr_scaler.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_arr_scaler.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
